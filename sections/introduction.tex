The use of Monte Carlo (MC) techniques to calculate nontrivial theoretical quantities and expectations in complex experimental settings is common practice in particle physics.
A MC event is a single representation of what can be detected in data and is typically generated from a single realization of the underlying physics parameters, $\vectheta_g$. These events are often binned in some observable space and compared with the data. Since the generation process is stochastic, a particular $\vectheta_g$ used for generating the MC can lead to different outputs. This stochasticity introduces an uncertainty in the MC distributions. Furthermore, as production of large MC is often time-consuming, reweighting is used to move from one hypothesis to another. In reweighting, each MC event is assigned a new weight, $w(\vectheta)$, that accounts for the difference between the generation parameters $\vectheta_g$ and the hypothesis parameters $\vectheta$~\cite{Gainer:2014bta}. It follows that MC uncertainties will be hypothesis dependent; thus, to do hypothesis testing, it is important to account for them. This is especially important for small-signal searches, performed in the small sample limit, where a modified-$\chi^2$ may not be suitable~\cite{Lyons:1986em}. A Poisson likelihood is a more appropriate statistical description of event counts~\cite{poisson1837recherches}, but in that case a proper treatment of MC statistical uncertainties is less straightforward. Solutions to this problem have been discussed in the literature in the context of frequentist statistics by adding nuisance parameters~\cite{Barlow:1993dm,Cranmer:2012sba,Chirkin:2013lya}, as well as detailed probabilistic treatment of MC weights~\cite{Glusenkamp:2017rlp}. However, \cite{Barlow:1993dm, Chirkin:2013lya, Glusenkamp:2017rlp} add additional time complexity, and \cite{Cranmer:2012sba} does not provide a full exposition on how to incorporate weighted MC. We present a new treatment that is valid in the large and small limit of the data sample size, suited for frequentist and Bayesian analyses, based on the Poisson likelihood. Our likelihood accounts for statistical uncertainties due to MC, allows for arbitrary event-by-event reweighting, and is computationally efficient. A test statistic based on the proposed likelihood is found to follow a distribution closer to the asymptotic form expected from Wilks' theorem. An implementation of the likelihood described in this work can be found in~\cite{MCLLH}.

This paper is organized as follows. In Sec.~\ref{sec:mc_intro} we briefly review two common treatments available in the literature to account for MC statistical uncertainty. In Sec.~\ref{sec:generalization_poisson} we define and discuss our new likelihood. In Sec.~\ref{sec:example} we study the performance of the likelihood through an example and compare it to other likelihoods in the literature. In Sec.~\ref{sec:conclusion} we provide our conclusions. A summary of the likelihoods discussed in the paper, including our main result, is given in Appendix~\ref{sec:appendixA}.

